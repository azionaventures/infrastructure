version: "1"

options:
  interpolation: true
  session_clean_before: False
  session_clean_after: False

env:
  AWS_ROLE_ARN: arn:aws:iam::${ACCOUNT_ID}:role/eks-deployer-role-${ENVIRONMENT}
  EKS_CLUSTER_NAME: ${EKS_CLUSTER_NAME}

targets:
  create-cluster:
    stages:
      describe-public-subnets:
          module: aziona.packages.aws.awscli
          before:
            echo: echo ${EKS_CLUSTER_NAME} ${EKS_K8S_VERSION} ${ENVIRONMENT}
          args:
            --action: ec2
            --xargs:
            --session-save: EKS_VPC_PUBLIC_SUBNETS
            --jq-query: |
              .Subnets |
              .[] |
              select(.Tags != null) |
              select(.Tags | .[] | .Value==\"${EKS_CLUSTER_NAME}-public\") | 
              \"--vpc-public-subnets=\"+.SubnetId
            --action-args: | 
              describe-subnets
              --output json
      describe-private-subnets:
          module: aziona.packages.aws.awscli
          args:
            --action: ec2
            --xargs:
            --session-save: EKS_VPC_PRIVATE_SUBNETS
            --jq-query: |
              .Subnets |
              .[] |
              select(.Tags != null) |
              select(.Tags | .[] | .Value==\"${EKS_CLUSTER_NAME}-private\") |
              \"--vpc-private-subnets=\"+.SubnetId
            --action-args: | 
              describe-subnets
              --output json
      create-cluster:
        module: aziona.packages.kubernetes.eksctl
        session:
          - EKS_VPC_PRIVATE_SUBNETS
          - EKS_VPC_PUBLIC_SUBNETS
        args:
          --action: create
          --action-args: |
            cluster
            --profile ${ORGANIZATION_NAME}
            --name ${EKS_CLUSTER_NAME}
            --version ${EKS_K8S_VERSION}
            --fargate
            ${EKS_VPC_PRIVATE_SUBNETS}
            ${EKS_VPC_PUBLIC_SUBNETS}
  delete-cluster:
    stages:
      delete-cluster:
        before:
          delete: kubectl delete deployments --all
        module: aziona.packages.kubernetes.eksctl
        args:
          --action: delete
          --action-args: |
            cluster
            --profile ${ORGANIZATION_NAME} 
            --name ${EKS_CLUSTER_NAME}
  kubetest:
    stages:
      assume-role-iam:
        module: aziona.packages.aws.iam.assume_role
        args: 
          --role-arn: ${AWS_ROLE_ARN}
          --role-session-name: assume-role-iam
          --role-session-duration: 1200
          --session-save: assume-role-iam
      kubeconfg:
        session: 
          - assume-role-iam
        type: bash
        module: kubectl get pods
        after:
          k: kubectl get pods -n kube-system
  kubeconfig:
    stages:
      kubeconfg:
        type: bash
        module: eksctl utils write-kubeconfig --cluster ${EKS_CLUSTER_NAME} --region ${EKS_AWS_REGION} --kubeconfig ${KUBECONFIG} 
  kubeconfig-role:
    stages:
      assume-role-iam:
        module: aziona.packages.aws.iam.assume_role
        args: 
          --role-arn: ${AWS_ROLE_ARN}
          --role-session-name: assume-role-iam
          --role-session-duration: 1200
          --session-save: assume-role-iam
      kubeconfig:
        session: 
          - assume-role-iam
        type: bash
        module: eksctl utils write-kubeconfig --cluster ${EKS_CLUSTER_NAME} --region ${EKS_AWS_REGION} --kubeconfig ${KUBECONFIG}
  kubeconfig-s3:
    stages:
      assume-role-iam:
        module: aziona.packages.aws.iam.assume_role
        args: 
          --role-arn: ${AWS_ROLE_ARN}
          --role-session-name: assume-role-iam
          --role-session-duration: 1200
          --session-save: assume-role-iam
        after:
          s3cp: aws s3 cp ${KUBECONFIG} s3://${KUBECONFIG_S3_BUCKET_LOCATION}/${EKS_CLUSTER_NAME}
